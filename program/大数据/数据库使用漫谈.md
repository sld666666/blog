## 数据库使用漫谈
本篇文章从一个订单系统的演化开始，详细介绍一个大型网站数据层的变动和技术的演讲。主要为了演示大数据量系统设计的演化过程。

这边文章从一个最简单的订单需求出发，跑完整个架构链路。
## 原始社会 - 裸操JDBC
互联网朦脓年代， 来了个需求，我需要开发一个订单系统，能根据订单标题查找我要的订单。

需求好简单， 我们直接设计表结构。 id, title, price。 设置title为索引。 选择JDBC作为数据操作的API层。 我们代码就非常简单。

```
  /**
  * Created by luodongshen on 2018/5/26.
  */
  public class JDBCExample {

    private Connection getMysqlConnection() {
        String driver = "com.mysql.jdbc.Driver";
        String url = "jdbc:mysql://localhost:3306/trade?useUnicode=true&characterEncoding=utf-8&useSSL=false";
        String username = "root";
        String password = "666666";
        Connection conn = null;
        try {
            Class.forName(driver); //classLoader,加载对应驱动
            conn = (Connection) DriverManager.getConnection(url, username, password);
        } catch (ClassNotFoundException e) {
            e.printStackTrace();
        } catch (SQLException e) {
            e.printStackTrace();
        }
        return conn;
    }

    public int insert(TradeDo tradeDo) {
        int rtn = -1;
        String sql = "insert into trade (title,price) values(?,?)";
        Connection conn = getMysqlConnection();
        PreparedStatement pstmt;
        try {
            pstmt = conn.prepareStatement(sql);
            pstmt.setString(1, tradeDo.getTitle());
            pstmt.setFloat((int)2, tradeDo.getPrice());
            rtn = pstmt.executeUpdate();
            pstmt.close();
            conn.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
        return rtn;
    }

    private List<TradeDo> query(String title) {
        List<TradeDo> tradeDos = new ArrayList<>();
        Connection conn = getMysqlConnection();
        String sql = "select * from trade";
        PreparedStatement pstmt;
        try {
            pstmt =  conn.prepareStatement(sql);
            ResultSet rs = pstmt.executeQuery();
            int col = rs.getMetaData().getColumnCount();
            System.out.println("============================");
            while (rs.next()) {
                TradeDo tradeDo = new TradeDo();
                for (int i = 1; i <= col; i++) {
                    if (1 == i) {
                        tradeDo.setId(rs.getLong(i));
                    }else if (2 == i) {
                        tradeDo.setTitle(rs.getString(i));
                    }else if (3 == i) {
                        tradeDo.setPrice(rs.getFloat(i));
                    }
                }
                System.out.println(tradeDo);
                tradeDos.add(tradeDo);
            }
            System.out.println("============================");
        } catch (SQLException e) {
            e.printStackTrace();
        }
        return tradeDos;
    }

    public static void main(String [] args){
        JDBCExample jdbcExample = new JDBCExample();
        Long time = System.currentTimeMillis();

        for (int i = 0; i < 1000; ++i) {
            TradeDo tradeDo = new TradeDo(Utils.getRandomString(40)
                    , Utils.getRandomFloaut());

            jdbcExample.insert(tradeDo);
        }

        System.out.println(String.format("insert 耗时：%d", System.currentTimeMillis() - time));

        time = System.currentTimeMillis();
        List<TradeDo> tradeDos = jdbcExample.query("aabbcc");
        System.out.println(String.format("query 耗时：%d", System.currentTimeMillis() - time));
    }
  }
```

### 采集社会 - ORM框架
这时候我们会发现两个问题：
1. 对数据库的连接没有很好得管理
2. 对数据的操作过程太麻烦了

这时候就需要 连接池框架和ORM框架来方便我们的开发了。 所以 mybatis+Druid 开始登场。

使用起来非常简单， 只要配置好即可，当然配置的过程中回发现出了问题找不到原因， 这就是框架使用的困扰。配置只需一下几步：

第一步： appilcaiton 配置文件
```
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.url=jdbc:mysql://localhost:3306/trade?useUnicode=true&characterEncoding=utf8&autoReconnect=true
spring.datasource.username=root
spring.datasource.password=666666
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.name=dbcp1
# 初始化大小，最小，最大
spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.poolPreparedStatements=true
spring.datasource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.filters=stat,wall
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
mybatis.mapper-locations=classpath*:mapper/*.xml
```
第二步： DruidDbConfig
```
@Component
public class DruidDbConfig {

    private static Logger logger = LoggerFactory.getLogger(DruidDbConfig.class);

    @Value("${spring.datasource.url}")
    private String dbUrl;

    @Value("${spring.datasource.username}")
    private String username;

    @Value("${spring.datasource.password}")
    private String password;

    @Value("${spring.datasource.driverClassName}")
    private String driverClassName;

    @Value("${spring.datasource.initialSize}")
    private int initialSize;

    @Value("${spring.datasource.minIdle}")
    private int minIdle;

    @Value("${spring.datasource.maxActive}")
    private int maxActive;

    @Value("${spring.datasource.maxWait}")
    private int maxWait;

    @Value("${spring.datasource.timeBetweenEvictionRunsMillis}")
    private int timeBetweenEvictionRunsMillis;

    @Value("${spring.datasource.minEvictableIdleTimeMillis}")
    private int minEvictableIdleTimeMillis;

    @Value("${spring.datasource.validationQuery}")
    private String validationQuery;

    @Value("${spring.datasource.testWhileIdle}")
    private boolean testWhileIdle;

    @Value("${spring.datasource.testOnBorrow}")
    private boolean testOnBorrow;

    @Value("${spring.datasource.testOnReturn}")
    private boolean testOnReturn;

    @Value("${spring.datasource.poolPreparedStatements}")
    private boolean poolPreparedStatements;

    @Value("${spring.datasource.maxPoolPreparedStatementPerConnectionSize}")
    private int maxPoolPreparedStatementPerConnectionSize;

    @Value("${spring.datasource.filters}")
    private String filters;

    @Value("{spring.datasource.connectionProperties}")
    private String connectionProperties;

    @Bean   //声明其为Bean实例
    @Primary  //在同样的DataSource中，首先使用被标注的DataSource
    public DataSource dataSource() {
        DruidDataSource datasource = new DruidDataSource();
        datasource.setUrl(this.dbUrl);
        datasource.setUsername(username);
        datasource.setPassword(password);
        datasource.setDriverClassName(driverClassName);
        //configuration
        datasource.setInitialSize(initialSize);
        datasource.setMinIdle(minIdle);
        datasource.setMaxActive(maxActive);
        datasource.setMaxWait(maxWait);
        datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis);
        datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis);
        datasource.setValidationQuery(validationQuery);
        datasource.setTestWhileIdle(testWhileIdle);
        datasource.setTestOnBorrow(testOnBorrow);
        datasource.setTestOnReturn(testOnReturn);
        datasource.setPoolPreparedStatements(poolPreparedStatements);
        datasource.setMaxPoolPreparedStatementPerConnectionSize(
                maxPoolPreparedStatementPerConnectionSize);
        try {
            datasource.setFilters(filters);
        } catch (SQLException e) {
            logger.error("druid configuration initialization filter", e);
        }
        datasource.setConnectionProperties(connectionProperties);
        return datasource;
    }

    @Bean
    public PlatformTransactionManager transactionManager() {
        return new DataSourceTransactionManager(dataSource());
    }
}
```
第三步： xml
```
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" >
<mapper namespace="com.example.demo.mapper.TradeMapper">
    <resultMap id="TradeMap" type="com.example.demo.TradeDo">
        <id column="id" property="id" jdbcType="INTEGER"/>
        <result column="title" property="title" jdbcType="VARCHAR"/>
        <result column="price" property="price" jdbcType="FLOAT"/>
    </resultMap>

    <sql id="Trade_Column_List">
		id,title,price
	</sql>

    <select id="query" resultMap="TradeMap" parameterType="java.lang.String">
        select
        <include refid="Trade_Column_List"/>
        from trade
        <![CDATA[
        where title like concat(#{title,jdbcType=VARCHAR},'%') LIMIT 0,5
        ]]>
    </select>

    <insert id="insertTrade" useGeneratedKeys="true" keyProperty="id"
            parameterType="com.example.demo.TradeDo">
        insert into trade
        <trim prefix="(" suffix=")" suffixOverrides=",">
            title, price
        </trim>
        values
        <trim prefix="(" suffix=")" suffixOverrides=",">
            #{title, jdbcType=VARCHAR},
            #{price, jdbcType=FLOAT},
        </trim>
    </insert>

</mapper>
```
第四步： mapper类
```
@Component
@Mapper
public interface TradeMapper {

    int insertTrade(TradeDo tradeDo);
    List<TradeDo> query(@Param("title") String title);
}
```
引入了ORM框架以后带来了几个额外的好处：
- 提高了开发效率
- 数据层维护更加简单

## 农业社会 - mycat
业务越来越快，数据量也来越多。单库单表的性能以及完全满足不了我们的需求，这是后就需要分库分表，或者直接上分布式数据库。
mycat是非常常用的分库分表中间件。mycat的使用非常简单：
1. 在conf下进行配置：
    a. server.xml: mycat把自己也认为是一台数据库，改配置是这台虚拟数据库的配置
    b. schema.xml: 虚拟数据库schema
    c. rules.xml: 分库分表规则
2. 使用：../bin/mycat start & stop
3. 看日志log下

继续有限的配置即可使用。
注： 全局序号配置本地模式时候每次重启时候会重新改变配置文件

### mycat 原理
![mycal原理.png](https://i.loli.net/2018/12/18/5c18e260c3811.png)
mycat的原理非常简单，加入一个额外的层次作为mycat-server作为SQL的路由。

其整体架构如下图所示：
![mycat架构.png](https://i.loli.net/2018/12/18/5c18e602a9f45.png)
整体而言mycat介就是解析输入sql，分发到不同的node(库或者表)中，然后处理其返回给应用系统
### mycat带来的好处
- 分布式数据库(横向扩容，大数据存储，微乎其微的性能开销)

## 工业时代 - redis+cannal
mycat带来解决了大数据量数据存储的问题，但是mysql的最大并发终归是有限的，对于高并发的场景，我们需要增加一层缓存来解决关键性的性能瓶颈。redis+cannal就能解决这个问题。

系统查询压力越来越大，对于部分数据可以查询热点数据使用redis存储, 使用cannal数据同步引擎
1. 开启mycal binlog,并配置binlog模式为row
2. canal的原理是模拟自己为mysql slave，所以这里一定需要做为mysql slave的相关权限

使用：
1. MySQL 默认没有开启 Binlog，因此我们需要对 my.cnf 文件做以下修改：
  ```
    server-id = 1
    log_bin = /path/to/mysql-bin.log
    binlog_format = ROW
  ```
2. 创建canal用户，用来管理canal的访问权限。我们可以通过对canal用户访问权限的控制，进而控制canal能够获取的内容。
```
CREATE USER canal IDENTIFIED BY 'canal';  
GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';
-- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ; 需要具有SHOW VIEW 权限
FLUSH PRIVILEGES;

```
3. 配置canal
```
1. 配置canna: conf/example/instance.properties
2. 启动cannal: bin/startup.sh
3. 看日志 logs/canal/cannal/logs
```
4. Java连接canal执行同步操作
```
<dependency>    
    <groupId>redis.clients</groupId>    
    <artifactId>jedis</artifactId>    
    <version>2.4.2</version>    
</dependency>
<dependency>    
    <groupId>com.alibaba.otter</groupId>    
    <artifactId>canal.client</artifactId>    
    <version>1.0.22</version>    
</dependency>

public  void syn() {

        // 创建链接
        //IP和端口为上文中 canal.properties中的IP和端口，“example”为默认，用户名密码不填
        CanalConnector connector = CanalConnectors.newSingleConnector(
                new InetSocketAddress("127.0.0.1",
                11111), "example", "", "");


        logger.info("正在连接...");
        System.out.println("正在连接...");
        System.out.println(connector);
        int batchSize = 1000;
        try {
            connector.connect();
            connector.subscribe(".*\\..*");
            logger.info("连接成功");
            System.out.println("连接成功");
            connector.rollback();
            while (true) {
                Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据
                long batchId = message.getId();
                int size = message.getEntries().size();
                if (batchId == -1 || size == 0) {
                    try {
                        Thread.sleep(1000);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                } else {
                    printEntry(message.getEntries());
                }

                connector.ack(batchId); // 提交确认
            }

        } finally {
            connector.disconnect();
            logger.info("连接释放成功");
            System.out.println("连接释放成功");
        }
    }
```

## cannal原理
![canal原理.png](https://i.loli.net/2018/12/18/5c18e8938c72d.png)
- canal利用了mysql的主从同步机制
- 把自己伪装成一个salve，从binlog中同步数据

## 信息化时代 - elasticsearch
业务场景越来越复杂，查询的复杂性也越来越高，显然简单的redies查询或者数据库like查询已经满足不了完的要求，这里就需要借助于搜索引擎了。

### 安装 elasticsearch
1. ./bin/elasticsearch
2. 验证是否启动 curl 'http://localhost:9200/?pretty'
3. 安装kibana: ./kikbana
4. 访问： http://localhost:5601 检查状态http://localhost:5601/status

### mysql到es数据同步
在往es数据同步上，借助于es的Rest客户端

```
@Autowired
  private RestClient restClient;
  HttpEntity httpEntity = new NStringEntity(JacksonUtil.beanToString(tradeDo),
           ContentType.APPLICATION_JSON);
   Response response = restClient.performRequest(
           "PUT", "/trade/id/"+id,
           Collections.singletonMap("pretty", "true"), httpEntity);
```

然后就可以查询了
```
  public String search(String tile) {
      String query = "title:";
      query+=tile;
      try {
          Response response = restClient.performRequest(
                  "GET", "/trade/_search",
                  Collections.singletonMap("q", query));
          return EntityUtils.toString(response.getEntity());
      } catch (IOException e) {
          e.printStackTrace();
      }

    return null;
}
```
### why elasticsearch?
首先为了查询速度最快，数据放内存比放硬盘肯定要搞。那么完全的内存数据库现实不？显然不现实。从查询效率的源头出发，我们尝试以如下方式来解决问题：
- 存储数据时候按有序存储
- 将数据和索引分离
- 压缩数据

这就引出了Elasticsearch.  Elasticsearch是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。

## 总结
本篇文章从最开始的数据层应用出发，从最简单的数据使用方式一路延伸到大数据量，高并发，复杂查询场景，延伸了相关中间件的使用。到最后整体互联网的底层架构如下图所示：
![互联网数据层架构.png](https://i.loli.net/2018/12/18/5c18f3ac85e33.png)
